---
layout: article
title: "48 interviews away from a Google offer"
image:
  teaser: 20230930-48-interviews-to-google/teaser.png
---



I've been looking for Applied ML scientist positions for quite a while, got rejections from 16 companies (mostly, bigtech and startups) and 2 offers. In an earlier post, I shared some helpful resources, here I'll share some high-level stats. 

Breakdown by interview type:

- Behavioral - 13.5
- Coding - 8.5
- ML breadth - 6
- ML depth - 5
- ML coding - 4
- Research presentation - 4
- ML system design - 3.5
- Take-home assignment - 3
- System design - 0.5

I was positively surprised that coding tasks were generally easy (think of Leetcode Easy mode), and I looked for senior+ positions, hence som many behaviorals. Also, for Applied ML Scientist roles you see a skew towards ML interviews and almost no system design interviews.

Interview leads (how did I get to the 1st interviews):

- Referral - 7
- Cold application - 4
- Reached out directly to the Hiring Manager - 4
- Recruiter/HM reaching out - 3
- Data Science communities - 2 

### Most common questions

I didn't record each end every one of course, but these stood out:

- p-value. Learn it by heart but also understand what it means
- in NLP-style ML breadth interviews, they all want you to explain the transformer or attention architecture. I made a post on how I take these questions
- Amazon is notoriously famous for puzzling behavioral questions like "tell me about a time you used data to adapt your strategy". Other companies and startups would rather ask you to describe successes, failures/conflicts, i.e. more expected stuff
- I was never (exactly 0 times) challenged to describe my weaknesses. Not sure if the importance of this question is overrated, just my experience 

### Interviews

Here are some highlights. 

#### Apple Music, ML Researcher for Recommender Systems, London

Got rejected after the first interview. They ended up hiring my former colleague who already lives in London and has way more experience with recommendation systems. Fair enough.

#### Aiforia, ML Team lead â€“ founded by folks from Yandex and Sber Devices, now in Cyprus

Passed the HM interview (mix of behavioral/technical).  Then a Kaggle grandmaster grilled me on "ML fundamentals."  Felt like light trolling tbh, haven't seen such tricky questions in ages. Some even started with "I don't know the answer to this one myself" lol.  Anyway, they were looking for experience with voice tech, which I don't have at all. So no hard feelings, didn't make the cut.

#### Replika

Saw their post in Vas3k club that they're looking for frontend devs, but you can reach out anyway. I wrote to the CTO, we chatted. Not exactly a perfect match, they needed researchers with a strong engineering focus.  

Lesson learned: no matter how much I want to emphasize Applied Science, I shouldn't use phrases like "messing around with configs" ðŸ™‚

####  Nvidia, Senior Applied Scientist

Pain and humiliation, they absolutely smashed me. I didn't just fail, but failed miserably.

Right off the bat, it was like "So, you think you're hot stuff?" What do you use for DPO? How have you done distributed model parallel? No? Only DDP? Ah, haven't touched 70b models? The interviewer was very polite, but that was the vibe.

Then it was okay. Transformers, NLP, all that jazz. Almost everyone asks about the transformer architecture.  Dude was dropping references to papers like Retro left and right, clearly well-read. But I think I held my own in the conversation.

I crumbled at the very first engineering question. What's the difference between storing variables on the stack and the heap? And how is that related to local/global variables? I didn't just forget, I don't think I ever even learned this. It took me two tries to even understand the question. The most I could mumble was something about the stack appearing during recursion. The peak of the interview was question #24:

<div style="text-align:center"><img src="/images/20230930-48-interviews-to-google/so_have_you_done_programming.jpg" width=500px /></div>


And algorithms: the "8 queens" problem. Classic, 101, according to the interviewer. Didn't have to write code, just describe the solution. But I started rambling about dynamic programming, then backtracking.  At least I correctly estimated the factorial complexity, but I still couldn't clearly describe the solution with DFS. Thought it was a simple problem, basic stuff, but it's actually a [hard](https://leetcode.com/problems/n-queens/description/) one.

NVIDIA is looking for rock stars, strong in both research and engineering. They can afford it, the job description for Senior Applied Scientist has a salary range for the US of 180-333k, and that's just the base. And their stock is through the roof. So it's all good.


<div style="text-align:center"><img src="/images/20230930-48-interviews-to-google/interview_embarrassment.jpg" width=500px /></div>


#### Cohere, Member of Technical Staff

Really liked these guys, the interviews were super reasonable.  Had a small coding test to optimize some Python code (got the same problem that a Kaggle grandmaster gave me before, so that interview wasn't a waste after all, heh). Instead of LeetCode, they had ML coding - I had to implement sampling from a simplified LLM decoder (greedy, top-k, top-p). ML system design was literally about an LLM evaluation system that Cohere is currently working on. I bet they get a lot of ideas from candidates :) And a paper review of my choice, also about LLM evaluation.  In the final round, I had a behavioral interview with the big boss, and there was no spark. Didn't get real feedback, just some excuse like "lacked the level of adaptability and speedy execution."


#### Snorkel AI, Staff Applied NLP Scientist

I got really emotionally attached to this option (don't do that before you have an offer). It's a startup founded by 5 PhDs from Stanford, growing rapidly, a unicorn.  They have a pretty coherent vision: companies don't need monsters with 1.8T parameters, they need specific models for their domain, fine-tuned on their data (YC agrees, ["Request for startups"](https://www.ycombinator.com/rfs): small fine-tuned models as an alternative to giant generic ones). Snorkel is all about programmatic data labeling, which saves experts time on labeling, and also uses LLMs for soft labels. Plus distillation/quantization - you get small and powerful models, Snorkel's blog is full of such stories ([example](https://snorkel.ai/better-not-bigger-how-to-get-gpt-3-quality-at-0-1-the-cost/)).

The interviews here were also very reasonable: behavioral first, then ML coding, ML system design, and a presentation about a research project. In that one I didn't show sufficient tech expertise but rather focused on leadership. I should have clarified with the recruiter which [staff archetype](https://staffeng.com/guides/staff-archetypes/) they need.


#### LLM Startup, VP AI (offer)

No-name startup, pre-seed, but the position is VP, I could have joined as the 6th employee, with a whole 1% of the company. Tempting, but I'm a coward and not doing a startup.

The interview was quite unusual - they sent me a doc in advance with ~20 questions about everything under the sun:

- "We're an LLM startup, why won't the next OpenAI update kill us?"
- "Hallucinations are critical in our business, what are we going to do about them?"
- "How will we integrate the research department into the company structure?".
- And even this: "Everyone is chasing GPUs now; maybe we'll be smarter and look at new chips?".  

For all the questions, I was asked to share my vision. Perhaps the most interesting interview. Initially, the CTO wanted to spend half an hour on LeetCode, but during the conversation, he was like, "okay, let's not waste time, the conversation is going well. High-bandwidth conversation."

#### Google Cloud, GenAI Field Solutions Architect (offer)

I got into Google through a referral, finally they didn't ignore me. Ironically, I was referred by a girl I helped leave Google to join Mistral. 

Google has gradually converged to a format of 4 interviews (it used to be 15-20). I had the following rounds:

- Leetcode + system design
- Role-related knowledge
- Leadership & googleyness
- General Cognitive Ability
- "casual" conversation with the manager

In the first round, the leetcode seemed easy and the design seemed difficult. I studied the design thoroughly (speaking of interview success being 50% effort and 50% luck, I haven't prepared this long for any other company). With big tech, you can ask for a couple of weeks to prepare, usually they are okay with this. And the mocks were very helpful, especially considering that I had never done a design interview before.

Role-related knowledge was about LLMs and consulting, there were a lot of questions about how to describe LLMs to clients, top managers, engineers. The technical questions didn't seem difficult (the "Generative AI with LLMs" [course](https://t.me/new_yorko_times/160) and my own experience with LLMs were enough), but for the business acumen and consulting questions, practice with business cases, like they do in big3, wouldn't hurt.

Leadership & googleyness is basically behavioral. Even though I mentor myself, I did 4 mocks, learning what exactly they want to hear in interviews for staff positions at Google. This was incredibly helpful.  As a result, I pretty thoroughly reworked my story bank.  Thankfully, there were no tricky, Amazon-style questions like "tell me how you used data to modify your strategy". Instead, it was more or less clear from the question what leadership qualities were being discussed and which of my stories to tell.

General Cognitive Ability is open-ended questions like "a friend opened a chocolate store, advise him on a business plan." There is a clear framework here, easy to practice. [This](https://www.youtube.com/@jeffhsipepi) YouTube channel by a former Google HR Jeff Sipe helped me a lot (there's a whole playlist about negotiations as well). I also took a consultation with a small mock, where I was advised to speak more slowly.

And the "casual" conversation with the manager - not casual at all, should be treated as behavioral. You can chat about life later, once they hire you, in the interview they look at signals. I prepared my strongest stories treating this as a behavioral interview.

Overall, I estimate the contribution of behavioral to be about 80%. Yeah, I didn't expect that could happen with Google. But this is a position in the Sales track, not SWE, I will have to communicate a lot with clients and top managers, so that's the focus.

### Conclusions 

Now the most important part. A long job search is mostly about your mental health and psychological stamina. I'd highlight the following considerations:

 - it's a marathon. Reserve 1 year for your job hunt. If done faster, great; otherwise, keep going
- it's a controlled lottery. Not just lottery (otherwise, you've got no lever to change anything) but a controlled one: you can improve your odds of winning by working hard but still treat this as a lottery
- respect your mental health. Just do what helps you: sports/yoga/art/etc. Don't do leetcode at 3am if you stand up at 7am
- don't get emotionally attached to any position before you get an offer. I did that a couple of times, and this only makes getting a rejection harder
- don't overthink it. Many people tend to think it's smth wrong with them or they suck or smth. No. The actual reason for rejection might be just location or another better candidate. One bigtech company ditched me after the 1st tech round, and turned out they hired my ex-colleague who's based in London and has more experience in recommender systems. And that's fine, I wouldn't have benefited from hours of self-reflection and wondering "why the heck did they ditch me?". So make constructive conclusions from your interview experience and move one. 

Good luck!


