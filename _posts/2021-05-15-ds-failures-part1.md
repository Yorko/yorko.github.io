---
layout: article
title: "[RUS] Data Science failures - part 1"
image:
  teaser: 20210515-ds-failures-part1/teaser.jpeg
---

_Here I honestly describe what people typically do not mention on their LinkedIn profiles – failures. This post is in Russian, originally [posted](https://vk.com/@mlcourse-nabitye-shishki-v-ds-pervaya-istoriya-iz-serii) in VK.com._

_[Here](https://youtu.be/c6dK1LWpv4g) is my conversation with the DataTalksClub leader Alexey Grigoriev about my Data Science failures, which is in English._

***

Привет! Скоро DataFest 2021, не упустите это море крутых докладов и нетворкинга. На датаёлке в прямом эфире кормили оленя, в этот раз обещают медведя, что, конечно же, главная причина сидеть в субботу в ютубе.


<div style="text-align:center"><img src="/images/20210515-ds-failures-part1/deer_natekin.jpg" /></div>

На фесте 2021 в треке про найм и карьеру в Data Science (ведомом Валерой Бабушкиным), я расскажу о своих набитых шишках и фэйлах в DS-проектах. Что-то в стиле LinkedIn vs. «true story», то есть о чем не пишут в профилях на LinkedIn. К слову, примерно о том же (только уже на английском) мы побеседуем с Алексеем Григорьевым через неделю после феста в его подкасте DataTalks ([анонс](https://datatalks.club/people/yurykashnitsky.html)).

В отличие от Валеры, я не работал на трёх работах одновременно, никогда не жал от груди два своих веса и вообще мне не очень комфортно, когда мои навыки объяснения логрега, условно, экстраполируют и считают, что я могу этим эйаем вам всем сейчас все метрики через потолок пробить и запустить в космос. Так что хочу рассказать свои историю про Data Science, как на практике порой сложно за счёт ML-моделей принести деньги компании, как сложно побить бейзлайны, и вот про это всё, пройтись, скажем так, критически по собственному LinkedIn-профилю.

### Ph.D.-guy в Mail.Ru Group

Начну рассказ про свой первый проект в Mail.Ru Group, куда я пришёл после 3х лет фултайм в аспирантуре ВШЭ. Я про это дело [рассказывал](https://www.youtube.com/watch?v=uK4hPD12YmI&t=4s) на DataFest 2018 в Минске (там про прочие косяки в анализе данных тоже есть), так что здесь вкратце, не смакуя подробности.

<iframe width="560" height="315" src="https://www.youtube.com/embed/uK4hPD12YmI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

У нас был большой крутой поисковый бустинг, использовали его заодно в рекомендациях контента – вот эти самые "читайте также" на куче площадок. Эвристика проста, как дверь – отсортировать по ClickThroughRate (заранее исключив обнажёнку и всякий непотребный контент). И в проде как раз было что-то типа недельного CTR в комбинации с месячным, чтоб тренд типа учесть, да все разбито на 10 поло-возрастных категорий. Ясное дело, у деревянных моделей офлайн результаты были сильно лучше.

Но в онлайн-эксперименте бустинг упорно проигрывал эвристике. Я проверил кучу ML-гипотез: active learning, лоссы специфичные для ранжирования, фичи всякие само собой (подошел к проблеме, как Ph.D.-guy) – так и не мог побить надежно эвристику. Месяца через 3 только понял, что дело в инфраструктуре, а не в ML части. Стресс-тест показал, что бустинг порой тормозил на инференсе, не укладывался в отведенные 80 мс, в таком случае подставлялся костыль (в поиске это называли ППН – поиск последней надежды). То есть по сути я в онлайне гонял не бустинг, а смесь бустинга с костылем.

Пофиксил – все взлетело. Фикс заключался в том, чтобы бустингу на переранжирование просто подавать меньше документов, чтоб он не захлебнулся. Опять, если интересно, детально про задачу, с метриками и всем прочим – в [докладе](https://www.youtube.com/watch?v=uK4hPD12YmI&t=4s) «О некоторых косяках в анализе данных». Но было поздно, отношения с боссом испорчены, и я сменил команду, хоть проект и успешный в итоге. Надо сказать, что примерно тогда же я стартанул mlcourse.ai и еще много делал по диссеру, так что я просто много на себя взвалил. В этой команде надо было фигачить фултайм, прям работать, к такому я не был готов после аспирантуры :)

### Выводы

Выводов я для себя сделал два (в отрыве от истории покажутся кэпскими) – ML-модель живет не в жупитер-ноутбуках, а в целой инфраструктуре, и чтоб «оно просто работало» – познакомься с разработчиками, обсуди в деталях, как работает эта самая инфраструктура, хотя бы та часть, что критична для твоей модели. Ну и второй вывод, что в некоторых ситуациях тебе надо работать сконцентрированно только над одной задачей, чтоб заработать репутацию.

Приходите на DataFest 2021, в том числе на секцию DS Hiring, где я расскажу о прочих граблях, по которым прошёлся в боевых проектах.

**UPD.** А вот и сам доклад.

<iframe width="560" height="315" src="https://www.youtube.com/embed/l5wLhhkLgHI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>